
# Introduction
世間一般には、LLM、AIの進化、多言語、大規模言語モデルをはじめとするAIの進化が進み、それらが人類の能力を大きく上回るといった話が出てきている。多言語モデル、大規模言語モデルは、その性能が日々進化し続けていて、計算や情報検索、高度な多量の情報の処理などにおいては、すでに人間を凌ぐパフォーマンスを発揮できるようになってきている。

しかし一方で、使用するエネルギーの効率性や処理にかかるスピード、特定の分野において熟達した人間の処理のスピードや正確さには、まだ及ばない領域があるのも事実である。例えば、同時通訳はその最たる例である。昨今、様々な大規模言語モデルが音声とテキストを統合した処理が可能になり、また複数のモデルを組み合わせた形で同時通訳を実現することが可能となってきている。

これは、スピーチとSPEECHというテキストや音声合成、あるいは言語情報の翻訳処理を可能にする言語モデルのマルチモーダル化、あるいはその言語モデル自体の性能の進化に支えられたものである。しかし、それらを組み合わせてもなお、音声から音声への同時通訳において、熟達した同時通訳者と同等のパフォーマンスやスピードを出せるAIやシステムの開発は至難の業であり、まだまだ課題が残されている。

まだまだ人間の同時通訳者のニーズや信頼があるのも事実である。今回の研究では、人間の高度に熟達した同時通訳者が同時通訳を行うために活用している脳内の神経基盤、そして脳内で行われている活動をひもとき、またそこから効率的にAIを活用し、同時通訳のシステムをシミュレーションし実装するためのヒントを得ることを目的としている。


同時通訳は音声や音声テキスト処理、統合処理、各単語の統合処理など、マルチモーダルな統合的な作業を行う非常に高度なタスクである。

今回の研究では、同時通訳における様々な活動のうち、特に入力された音声を保管しておき、その音声を通訳を始めるタイミングを判断するための情報として活用する活動に目を向け、それを効率的に行うための脳基盤を特定し、そこからそれをモデル化し、実装可能なモデルへと昇華することを目的とする。

# Cognitive load Model 
[ ここに、同時通訳に関する認知科学的な研究、同時通訳の処理中に人間が行う認知科学的なアプローチをモデル化した過去のセオリー、それとに関わる対象、対応する脳活動の脳基盤、そしてそれを証明する論文の引用とともに、どのような活動が脳内で行われているかということを論じる。]

# Therory and design


# Implementation
[上記のものをもとに、それを実際にPythonなどのコードで実装可能なモデルへと落とします。]

# Simulation
[そのモデルに対してデータの入力、コーパスデータなどから取得したデータを基に実際に入力を行い、その時に脳内にかかる負荷をモデル化し、その処理のために必要とするメモリ量や脳内の活動量をモデル化してみる。そのために必要な計算量とパラメータ数、データの保持に必要な情報量を割り出してみます。]

# Result
結果としては、これを同じことをAIで現状、AIではこれらよりも圧倒的に多いパラメータ下において計算を行っており、そこではまだパフォーマンスやコスパの良さという面では、高度にその能力に熟達した人間の方が圧倒的に高いことがわかります。

現状、世の中で採用されているモデルの多くは、一般的に音声認識や言語処理に関しても、アノテーションされたデータを基に、そのモデルによって学習を行い、予測モデルを作ることを前提としています。

今回の実験により、脳の神経活動を参照することによって、実際の人間の通訳者が通訳を効率的に行うため、素早く行うために取る戦略の一部を参照させ、また、神経科学的に裏付けられた活動を参照し、それをモデル化へと落とし込むことによって、効率の良い通訳の処理を行える可能性が示唆されました。

# Discussion
今後の課題としては、このモデルはまだ実装されておらず、あくまでPythonベースのMockであるため、実際にこれを機械学習、あるいは計算機としてプロダクションで運用可能なスピードへと昇華する必要があります。また、これをモデルに落とし込むために必要となるデータやその形式に関してはまだ不透明であり、そこに関しては研究の要望が求められます。

また、今回の論文において考慮できていない点としては、今回は同時通訳を行う際に人が取る形である情報のバッファリング、テキストのバッファリング、そして予測という点に焦点を当てて研究を行いましたが、これ以外にもLLMやAIを前提としたモデルならではの、それぞれに軍配があることは事実である。例えば、以前から言語の判定をするモデル、言語の識別というのはかなり一般的に行われているものであり、人間の場合は言語の判定という面に関して言えば、音の特性、また本人との紐付け、その言語をもともと話していた本人との紐付け、映像との紐付けなどの補足情報も大変多分に考慮して、言語の判定や予測を行っている可能性が高い。 これと同じことをAIで実現しようとすると、マルチモーダルなモデルで莫大な大きさのモデルが必要となることは現状事実であり、これはまだ実現が難しいと考えます。このように、全てを人間の行っている活動を基にすればいいというわけではなく、AIにおける優位性やそれが得意なこと、現状の技術的な制約も理解しながら、現実的に実用・活用可能な神経基盤を参照し、それを参考にモデルや機械とのそれぞれの特性を加味しながら、最も効果的な活動を行う方法を模索する必要があります。


問1
1. 熟達した同時通訳者の高度な同時通訳処理を可能にする脳の神経基盤は何か？
- 先行研究から推定できる
2. 


考えてもいいこととしては、脳内の神経基盤とそこに行われている実際の事実、脳内で実際に行われている脳活動をベースにした、その機構を模した同時AIによるシステム的なリアルタイム同時通訳システムのアーキテクチャの提案。


今、世の中にある同時通訳のシステムというのは、基本的にSST (Speech-to-Text)、LLMによる翻訳、そしてTTS (Text-to-Speech) による出力という三段構成になっている。基本的にはこれらを模した形を取ることが一般的です。

しかし、これらのAIのモデルにおいては、まだ人による同時通訳のパフォーマンスを完全に超えることはできておらず、また人のような柔軟な通訳の戦略を行うことは難しいと考えられています。本論文では、過去に提唱されている同時通訳時における人の同時通訳の精度を高めるための人の同時通訳の適応戦略を、SVOとSOVという言語構造が非対称な言語間におけるタスク時の戦略について注目し、脳内の実際の復活化、そこで行われている脳内の活動から、最終的にそれを模したシステムの実装のアーキテクチャの提案を行うことを目的とする。

Kilian Seeberの認知負荷モデル
キリアン・シーバーが提案した認知負荷モデルの中においては、彼は言語構造が非対称な言語において、通訳タスク時、人はいくつかの適応戦略を行うと考えている。那は、待機、引き延ばし、チャンキング、予測の4つである。

-

待機というのはその名の通り、通訳の産出を一時停止してより多くの元言語の入力を待つ戦略である。那は待機中に受け取った情報がワーキングメモリに格納され、トランスレーションで符号化されるまで活性化された状態を維持する必要がある。この時点ではシステム的にはこれらのデータを廃棄することができないためである。
蓄積したデータが多くなればなるほど、過流で一気に認知負荷、処理の負荷がかかることがあげられる。引き延ばしにおいては、待機と非常に似ている。
これに対応する処理は 脳内の ... で行われていると


引き延ばしは待機と非常に似ており、統合・符号化段階の前に、より多くの入力を得るための時間稼ぎを目的としています。待機が沈黙の期間を生むのに対し、引き延ばしは「中立的な埋め草」を産出します。つまり、メッセージに新しい情報を追加することなく、通訳の遅延を増やします。引き延ばしのために何らかの符号の産出を行うことで、処理の複雑さが加わり、待機に比べて認知負荷が増加します。

チャンキングでは、通訳者が入力をより小さな断片に分解し、文全体が展開するのを待つことなく符号化できる戦略です。即座の統合と符号化が可能である一方で、主要動詞がないために、仮打ちのプロセスにおいてチャンクをつなぎ合わせて元の意味を確立または回復する必要があり、一時的に遅延した認知負荷の増加を引き起こします。結果として、生じる構造が複雑になったり、言語に反するほど不自然になったりすることがあります。

予測は、通訳者が話者が発話する前に元の談話を一部予測する能力を指します。この戦略は、他の2つに比べて2つの大きな利点があります。まず、実際の推論処理を除けば、認知的資源要求は基準値に近いままである点です。次に、通訳者は基準値と同様の遅延で通訳を終えることができ、前述のスピルオーバー効果を防ぐことができます。

